{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 개발 팁\n",
    "\n",
    "## 목차\n",
    "\n",
    "  1. GPU 사용 방식 설정\n",
    "    - `config.gpu_options.allow_growth = True`\n",
    "    - `CUDA_VISIBLE_DEVICES`\n",
    "  1. 모델의 저장과 복원\n",
    "    - `tf.train.Saver()`\n",
    "  1. 그래프의 저장과 복원\n",
    "    - `tf.train.export_meta_graph()`\n",
    "    - `tf.train.import_meta_graph()`\n",
    "  1. 저장된 모델을 텐서플로우 외부에서 확인\n",
    "    - `inspect_checkpoint.py`\n",
    "  1. 그래프의 finalize\n",
    "    - `tf.get_default_graph().finalize()`\n",
    "  1. 그래프의 reset\n",
    "    - `tf.reset_default_graph()`\n",
    "  1. 텐서 수치오류 체크\n",
    "    - `tf.check_numerics(tensor,messge)`\n",
    "  1. 파이썬 디버거 pdb 사용법\n",
    "    - `python -m pdb myscript.py`\n",
    "    - jupyter notebook 에서 `debug`\n",
    "  1. 텐서플로우 디버거 tfdbg\n",
    "    - `sess = tf_debug.LocalCLIDebugWrapperSession(sess)`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 사용 방식 설정\n",
    "\n",
    "### `tf.ConfigProto`\n",
    "\n",
    "- http://devdocs.io/tensorflow~python/tf/configproto\n",
    "- https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/protobuf/config.proto\n",
    "\n",
    "<code>\n",
    "    config = tf.ConfigProto()\n",
    "    <span style=\"color:red\">config.gpu_options.allow_growth = True</span>\n",
    "    ...\n",
    "    session = tf.Session(config=config)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [`CUDA_VISIBLE_DEVICES`](https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/)\n",
    "\n",
    "- 여러개의 GPU가 장착된 시스템에서 사용시, 특정 GPU만 선택해서 사용하도록 설정\n",
    "\n",
    "        CUDA_VISIBLE_DEVICES=0,1\n",
    "\n",
    "- GPU가 있는 시스템에서, CPU만 사용하도록 만들 때도 사용 가능\n",
    "\n",
    "        CUDA_VISIBLE_DEVICES=-\n",
    "\n",
    "- 환경변수로 저장\n",
    "\n",
    "        export CUDA_VISIBLE_DEVICES=0,1\n",
    "        python ...\n",
    "\n",
    "- 필요시 ~/.bashrc 파일에 추가하면 로그인 할 때마다 적용\n",
    "\n",
    "- 참고: http://acceleware.com/blog/cudavisibledevices-masking-gpus\n",
    "\n",
    "\n",
    "#### 주의사항\n",
    "\n",
    "- _GPU 번호가 `nvidia-smi`에서 보여주는 번호와 다를 수 있습니다._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 저장과 복원\n",
    "\n",
    "### 모델 파라메터의 저장과 복원\n",
    "\n",
    "#### **[`tf.train.Saver`](http://devdocs.io/tensorflow~python/tf/train/saver)**\n",
    "\n",
    "<code>\n",
    "    tf.train.Saver(\n",
    "        <span style=\"color:red\">var_list=None,</span>\n",
    "        reshape=False,\n",
    "        sharded=False,\n",
    "        max_to_keep=5,\n",
    "        keep_checkpoint_every_n_hours=10000.0,\n",
    "        name=None,\n",
    "        restore_sequentially=False,\n",
    "        saver_def=None,\n",
    "        builder=None,\n",
    "        defer_build=False,\n",
    "        allow_empty=False,\n",
    "        write_version=tf.train.SaverDef.V2,\n",
    "        pad_step_number=False,\n",
    "        save_relative_paths=False\n",
    "    )\n",
    "</code>\n",
    "\n",
    "### 모델 파라메터 저장\n",
    "\n",
    "#### [_`saver`_**`.save()`**](http://devdocs.io/tensorflow~python/tf/train/saver)\n",
    "\n",
    "<code>\n",
    "    save(\n",
    "        <span style=\"color:red\">sess,</span>\n",
    "        <span style=\"color:red\">save_path,</span>\n",
    "        <span style=\"color:red\">global_step=None,</span>\n",
    "        latest_filename=None,\n",
    "        meta_graph_suffix='meta',\n",
    "        write_meta_graph=True,\n",
    "        write_state=True\n",
    "    )\n",
    "</code>\n",
    "\n",
    "> Returns:\n",
    "> A string: path at which the variables were saved. If the saver is sharded, this string ends with: '-?????-of-nnnnn' where 'nnnnn' is the number of shards created. If the saver is empty, returns None.\n",
    "\n",
    "### 모델 파라메터 복원\n",
    "\n",
    "#### [_`saver`_.**`restore()`**](http://devdocs.io/tensorflow~python/tf/train/saver)\n",
    "\n",
    "<code>\n",
    "    restore(\n",
    "        <span style=\"color:red\">sess,</span>\n",
    "        <span style=\"color:red\">save_path</span>\n",
    "    )\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장 복원 예시\n",
    "\n",
    "### MNIST 데이터 준비 (1주 3일차 데이터 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "test -s ./mnist/train-images-idx3-ubyte || (\n",
    " mkdir -p ./mnist\n",
    " cd ./mnist\n",
    " echo \"$(pwd)\"\n",
    " wget -q \\\n",
    "  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz \\\n",
    "  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz \\\n",
    "  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \\\n",
    "  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    " gzip -d *.gz\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './mnist'\n",
    "data_dir\n",
    "\n",
    "images         = np.fromfile(data_dir + \n",
    "                     '/train-images-idx3-ubyte',dtype=np.uint8)\n",
    "images         = images[16:].reshape([-1,28,28]).astype(np.float32)\n",
    "images         = images / 127.0 - 1.0\n",
    "\n",
    "labels         = np.fromfile(data_dir + \n",
    "                     '/train-labels-idx1-ubyte',dtype=np.uint8)\n",
    "labels         = labels[8:].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('float32'), (60000,), dtype('int64'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, images.dtype, labels.shape, labels.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 훈련 네트워크 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    '''\n",
    "    simple 1-layer fully-connected network for MNIST problem\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        learning_rate = 0.05\n",
    "        input_size    = 28 * 28\n",
    "        output_size   = 10\n",
    "\n",
    "        with tf.name_scope('data'):\n",
    "            input_        = tf.placeholder(\n",
    "                shape=[None, input_size],\n",
    "                dtype=tf.float32, name=\"input\")\n",
    "            label         = tf.placeholder(\n",
    "                shape=[None], \n",
    "                dtype=tf.int64, name=\"label\")\n",
    "        with tf.name_scope('fcn'):\n",
    "            weights       = tf.Variable(\n",
    "                tf.zeros([input_size, output_size]))\n",
    "            biases        = tf.Variable(\n",
    "                tf.zeros([output_size]))\n",
    "            output        = tf.matmul(input_, weights) + biases\n",
    "\n",
    "        with tf.name_scope('optimize'):\n",
    "            loss          = \\\n",
    "                tf.losses.sparse_softmax_cross_entropy(\n",
    "                    label,\n",
    "                    output)\n",
    "            optimize      = \\\n",
    "                tf.train.AdamOptimizer(learning_rate) \\\n",
    "                    .minimize(loss)\n",
    "\n",
    "        with tf.name_scope('prediction'):\n",
    "            pred          = tf.argmax(output, \n",
    "                                      axis=1, \n",
    "                                      name='pred')\n",
    "            accuracy      = \\\n",
    "                1.0 - \\\n",
    "                tf.cast(\n",
    "                    tf.count_nonzero(pred-label),\n",
    "                    tf.float32) / \\\n",
    "                tf.cast(tf.size(label),tf.float32)\n",
    "\n",
    "        self.input    = input_\n",
    "        self.label    = label\n",
    "        self.loss     = loss\n",
    "        self.optimize = optimize\n",
    "        self.pred     = pred\n",
    "        self.accuracy = accuracy\n",
    "        self.weights  = weights\n",
    "        self.biases   = biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,max_epochs=20):\n",
    "\n",
    "    batch_size    = 128\n",
    "    batch_count   = 60000 // batch_size\n",
    "\n",
    "    step          = 1\n",
    "\n",
    "    config = tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for ep in range(max_epochs):\n",
    "            total_loss       = 0\n",
    "            total_acc_v      = 0\n",
    "            for i in range(batch_count):\n",
    "                img = np.reshape(\n",
    "                        images[i*batch_size:(i+1)*batch_size],\n",
    "                        [batch_size, 28 * 28])\n",
    "                lbl = (labels[i*batch_size:(i+1)*batch_size])\n",
    "                _, loss_v, acc_v = \\\n",
    "                  session.run(\n",
    "                    [model.optimize,\n",
    "                     model.loss,\n",
    "                     model.accuracy],\n",
    "                    feed_dict= {\n",
    "                        model.input: img,\n",
    "                        model.label: lbl})\n",
    "                step        += 1\n",
    "                total_loss  += loss_v\n",
    "                total_acc_v += acc_v\n",
    "                \n",
    "                # <<<=== 주기적으로 save ===>>>\n",
    "                ##################################################\n",
    "                # 2000 step 마다 save/example 에 저장\n",
    "                ##################################################\n",
    "                if step % 2000 == 0:\n",
    "                    checkpoint = saver.save(session,\n",
    "                                            'save/example',\n",
    "                                            global_step=step)\n",
    "                    print('Saved: %s'%(checkpoint,))\n",
    "\n",
    "\n",
    "            print('ep %d: loss: %.5f acc: %.3f%%' % (\n",
    "                ep+1,\n",
    "                total_loss / batch_count,\n",
    "                total_acc_v / batch_count * 100))\n",
    "\n",
    "        ##################################################\n",
    "        # save/graph 에 저장\n",
    "        ##################################################\n",
    "            \n",
    "        tf.train.export_meta_graph(filename='save/graph')\n",
    "\n",
    "        ##################################################\n",
    "        # save/example 에 저장\n",
    "        ##################################################\n",
    "            \n",
    "        checkpoint = saver.save(session,\n",
    "                                'save/example',\n",
    "                                global_step=step)\n",
    "        print('Saved: %s'%(checkpoint,))\n",
    "        \n",
    "        \n",
    "        writer = tf.summary.FileWriter(\n",
    "            'save',\n",
    "            tf.get_default_graph())\n",
    "\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: loss: 2.14669 acc: 82.175%\n",
      "ep 2: loss: 1.65718 acc: 85.445%\n",
      "ep 3: loss: 1.94722 acc: 85.882%\n",
      "ep 4: loss: 2.05991 acc: 86.485%\n",
      "Saved: save/example-2000\n",
      "ep 5: loss: 1.99479 acc: 86.988%\n",
      "ep 6: loss: 2.04258 acc: 87.023%\n",
      "ep 7: loss: 2.02497 acc: 87.336%\n",
      "ep 8: loss: 2.11884 acc: 87.238%\n",
      "Saved: save/example-4000\n",
      "ep 9: loss: 2.04744 acc: 87.570%\n",
      "ep 10: loss: 2.03975 acc: 87.690%\n",
      "ep 11: loss: 1.98439 acc: 87.857%\n",
      "ep 12: loss: 2.10790 acc: 87.630%\n",
      "Saved: save/example-6000\n",
      "ep 13: loss: 2.15829 acc: 87.759%\n",
      "ep 14: loss: 2.23853 acc: 87.727%\n",
      "ep 15: loss: 2.06537 acc: 88.418%\n",
      "ep 16: loss: 2.12343 acc: 88.103%\n",
      "ep 17: loss: 2.09931 acc: 88.303%\n",
      "Saved: save/example-8000\n",
      "ep 18: loss: 2.14287 acc: 88.134%\n",
      "ep 19: loss: 2.19149 acc: 88.086%\n",
      "ep 20: loss: 2.12249 acc: 88.361%\n",
      "Saved: save/example-9361\n"
     ]
    }
   ],
   "source": [
    "train(model,20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1808\r\n",
      "-rw-r--r--   1 rhee  staff  52981 Sep  8 11:03 example-2000.meta\r\n",
      "-rw-r--r--   1 rhee  staff    343 Sep  8 11:03 example-2000.index\r\n",
      "-rw-r--r--   1 rhee  staff  94208 Sep  8 11:03 example-2000.data-00000-of-00001\r\n",
      "drwxrwxr-x  29 rhee  staff    986 Sep  8 11:03 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 rhee  staff  52981 Sep  8 11:03 example-4000.meta\r\n",
      "-rw-r--r--   1 rhee  staff    343 Sep  8 11:03 example-4000.index\r\n",
      "-rw-r--r--   1 rhee  staff  94208 Sep  8 11:03 example-4000.data-00000-of-00001\r\n",
      "-rw-r--r--   1 rhee  staff  52981 Sep  8 11:03 example-6000.meta\r\n",
      "-rw-r--r--   1 rhee  staff    343 Sep  8 11:03 example-6000.index\r\n",
      "-rw-r--r--   1 rhee  staff  94208 Sep  8 11:03 example-6000.data-00000-of-00001\r\n",
      "-rw-r--r--   1 rhee  staff  52981 Sep  8 11:03 example-8000.meta\r\n",
      "-rw-r--r--   1 rhee  staff    343 Sep  8 11:03 example-8000.index\r\n",
      "-rw-r--r--   1 rhee  staff  94208 Sep  8 11:03 example-8000.data-00000-of-00001\r\n",
      "-rw-r--r--   1 rhee  staff  52911 Sep  8 11:03 graph\r\n",
      "-rw-r--r--   1 rhee  staff  52981 Sep  8 11:03 example-9361.meta\r\n",
      "-rw-r--r--   1 rhee  staff    343 Sep  8 11:03 example-9361.index\r\n",
      "-rw-r--r--   1 rhee  staff  94208 Sep  8 11:03 example-9361.data-00000-of-00001\r\n",
      "-rw-r--r--   1 rhee  staff    253 Sep  8 11:03 checkpoint\r\n",
      "drwxr-xr-x  20 rhee  staff    680 Sep  8 11:03 \u001b[34m.\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 rhee  staff  98509 Sep  8 11:03 events.out.tfevents.1504836214.rhee-mbp.local\r\n"
     ]
    }
   ],
   "source": [
    "!ls -altr save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기서 잠깐, 텐서보드 그래프 기능 한 번 확인 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 54 at http://rhee-mbp.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 모델 파라메터의 복원\n",
    "\n",
    "#### 모델 파라메터 텐서는 문자열로 표현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'prediction/pred:0', u'data/input:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred.name, model.input.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'prediction/pred:0', u'data/input:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred.name, model.input.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def infer(image, label):\n",
    "\n",
    "    config = tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        ##################################################\n",
    "        # save/example 에 저장한 파일로 부터 복원\n",
    "        ##################################################\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(session, 'save/example-9361')\n",
    "\n",
    "        pred = session.run(\n",
    "            # model.pred\n",
    "            'prediction/pred:0',\n",
    "            # model.input\n",
    "            {'data/input:0':[image.reshape([28*28])]})\n",
    "\n",
    "        print('infer: label={}, pred={}'.format(label,pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/example-9361\n",
      "infer: label=3, pred=3\n"
     ]
    }
   ],
   "source": [
    "infer(images[1234],labels[1234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프의 저장과 복원\n",
    "\n",
    "### 그래프 저장\n",
    "\n",
    "#### [`tf.train.export_meta_graph('save/graph')`](http://devdocs.io/tensorflow~python/tf/train/export_meta_graph)\n",
    "\n",
    "<code>\n",
    "    tf.train.export_meta_graph(\n",
    "        <span style=\"color:red\">filename=None,</span>\n",
    "        meta_info_def=None,\n",
    "        graph_def=None,\n",
    "        saver_def=None,\n",
    "        collection_list=None,\n",
    "        as_text=False,\n",
    "        graph=None,\n",
    "        export_scope=None,\n",
    "        clear_devices=False,\n",
    "        **kwargs\n",
    "    )\n",
    "</code>\n",
    "\n",
    "### 그래프 복원\n",
    "\n",
    "#### [`tf.train.import_meta_graph('save/graph')`](http://devdocs.io/tensorflow~python/tf/train/import_meta_graph)\n",
    "\n",
    "<code>\n",
    "    import_meta_graph(\n",
    "        <span style=\"color:red\">meta_graph_or_file,</span>\n",
    "        clear_devices=False,\n",
    "        import_scope=None,\n",
    "        **kwargs\n",
    "    )\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 그래프와 모델 파라메터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.saver.Saver at 0x11a7169d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# model = Model()  # <<<==== 만들 필요 없음\n",
    "tf.train.import_meta_graph('save/graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/example-9361\n",
      "infer: label=3, pred=3\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def infer(image, label):\n",
    "\n",
    "    config = tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        ##################################################\n",
    "        # save/example 에 저장한 파일로 부터 복원\n",
    "        ##################################################\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(session, 'save/example-9361')\n",
    "\n",
    "        model_input = 'data/input:0'\n",
    "        model_pred  = 'prediction/pred:0'\n",
    "\n",
    "        pred = session.run(\n",
    "                    model_pred,\n",
    "                    {model_input:[image.reshape([28*28])]})\n",
    "\n",
    "        print('infer: label={}, pred={}'.format(label,pred[0]))\n",
    "\n",
    "\n",
    "infer(images[1234],labels[1234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제로 전혀 다른 파이썬 인터프리터로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pycat restore_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-08 11:03:53.163645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-08 11:03:53.163666: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-08 11:03:53.163670: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-08 11:03:53.163674: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "infer: label=3, pred=3\n"
     ]
    }
   ],
   "source": [
    "!python restore_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 저장과 복원 정리\n",
    "\n",
    "#### 파라메터 저장\n",
    "\n",
    "    # 모든 파라메터 저장 (trainable/non-trainable 구별은 하지 않음)\n",
    "    saver = tf.train.Saver()\n",
    "    saver_checkpoint = saver.save(sess, 'save/my-model', global_step=step)\n",
    "\n",
    "    # 선택한 파라메터만 저장\n",
    "    selected_saver = tf.train.Saver([model.w1,model.w2])\n",
    "    selected_saver.save(sess, 'save2/weights', global_step=step)\n",
    "\n",
    "    # scope 속성을 활용한 파라메터 선택\n",
    "    export_saver = tf.train.Saver( \\\n",
    "        tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='my_block'))\n",
    "    export_saver.save(sess, 'export/my-block', global_step=step)\n",
    "\n",
    "> [`tf.get_collection`](http://devdocs.io/tensorflow~python/tf/get_collection) 을 이용해서 원하는 텐서의 목록을 얻음\n",
    "\n",
    "> [`tf.GraphKeys`](http://devdocs.io/tensorflow~python/tf/graphkeys)`.GLOBAL_VARIABLES` 를 지정해서 모든 글로벌 파라메터의 목록을 얻을 수 있음\n",
    "\n",
    "#### 파라메터 복원\n",
    "\n",
    "    # checkpoint 경로를 미리 알고 있다면\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, saver_checkpoint)\n",
    "\n",
    "    # 지정 디렉토리 'save'에서 가장 최근의 체크포인트 경로를 읽어옴\n",
    "    checkpoint = tf.train.latest_checkpoint('save')\n",
    "    saver_for_restore = tf.train.Saver()\n",
    "    saver_for_restore.restore(sess, checkpoint)\n",
    "\n",
    "    # 모든 파라메터를 다 읽어오지 않고, 정해진 파라메터들만 읽어오고 싶다면\n",
    "    import_checkpoint = tf.train.latest_checkpoint('export')\n",
    "    import_saver = tf.train.Saver( \\\n",
    "        tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \\\n",
    "                          scope='my_block'))\n",
    "    import_saver.restore(sess,import_checkpoint)\n",
    "\n",
    "#### 그래프 저장\n",
    "\n",
    "    tf.train.export_meta_graph(filename='save/graph')\n",
    "\n",
    "#### 그래프 복원\n",
    "\n",
    "    tf.train.import_meta_graph('save/graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 모델을 텐서플로우 외부에서 확인\n",
    "  - `inspect_checkpoint.py`\n",
    "  - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: inspect_checkpoint --file_name=checkpoint_file_name [--tensor_name=tensor_to_print]\r\n"
     ]
    }
   ],
   "source": [
    "!python -mtensorflow.python.tools.inspect_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn/Variable (DT_FLOAT) [784,10]\n",
      "fcn/Variable/Adam (DT_FLOAT) [784,10]\n",
      "fcn/Variable/Adam_1 (DT_FLOAT) [784,10]\n",
      "fcn/Variable_1 (DT_FLOAT) [10]\n",
      "fcn/Variable_1/Adam (DT_FLOAT) [10]\n",
      "fcn/Variable_1/Adam_1 (DT_FLOAT) [10]\n",
      "optimize/beta1_power (DT_FLOAT) []\n",
      "optimize/beta2_power (DT_FLOAT) []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -mtensorflow.python.tools.inspect_checkpoint \\\n",
    "  --file_name 'save/example-9361'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프의 finalize()\n",
    "\n",
    "### [`tf.get_default_graph().finalize()`](http://devdocs.io/tensorflow~python/tf/graph)\n",
    "\n",
    "> Finalizes this graph, making it read-only.\n",
    "\n",
    "> After calling g.finalize(), no new operations can be added to g. This method is used to ensure that no operations are added to a graph when it is shared between multiple threads, for example when using a tf.train.QueueRunner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph is finalized and cannot be modified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b1f25a1fad0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mone_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n\u001b[1;32m    105\u001b[0m       \u001b[0;34m\"Const\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m     \"\"\"\n\u001b[0;32m-> 2458\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2459\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_check_not_finalized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \"\"\"\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2181\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph is finalized and cannot be modified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Graph is finalized and cannot be modified."
     ]
    }
   ],
   "source": [
    "tf.get_default_graph().finalize()\n",
    "one_ = tf.constant(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 reset()\n",
    "\n",
    "### [`tf.reset_default_graph()`](http://devdocs.io/tensorflow~python/tf/reset_default_graph)\n",
    "\n",
    "> Clears the default graph stack and resets the global default graph.\n",
    "\n",
    "> NOTE: The default graph is a property of the current thread. This function applies only to the current thread. Calling this function while a tf.Session or tf.InteractiveSession is active will result in undefined behavior. Using any previously created tf.Operation or tf.Tensor objects after calling this function will result in undefined behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "one_ = tf.constant(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 수치오류 체크\n",
    "\n",
    "### `tf.check_numerics(tensor,messge)`\n",
    "\n",
    "    tf.check_numerics(\n",
    "        tensor,\n",
    "        message,\n",
    "        name=None\n",
    "    )\n",
    "\n",
    "> Checks a tensor for NaN and Inf values.\n",
    "\n",
    "> When run, reports an InvalidArgument error if tensor has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes tensor as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x11a727310>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x11a727310>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_ = tf.constant(0.0)\n",
    "minus_one_ = tf.constant(-1.0)\n",
    "c_minus_one_ = tf.constant(-1.0,dtype=tf.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, (-1+0j))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus_one_.eval(), c_minus_one_.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 으로 나눈다고 exception 이 바로 발생하지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_by_zero_ = tf.div(tf.constant(1.0), zero_)\n",
    "div_by_zero_.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1 제곱근을 구해도 exception 발생하지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_minus_one_ = tf.sqrt(tf.constant(-1.0))\n",
    "sqrt_minus_one_.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잠깐 주의: 텐서플로우는 복소수 타입도 지원합니다.\n",
    "\n",
    "- 하지만 모델 작성에 사용하실 때는 복소수 타입이 지원 안되는 연산이 많다는 것에 유의\n",
    "  (https://stackoverflow.com/questions/42284904/complex-gradients-on-gpu-in-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.5497901e-08+1j)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_c_minus_one_ = tf.sqrt(tf.constant(-1.0,dtype=tf.complex64))\n",
    "sqrt_c_minus_one_.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 의 로그 값을 계산해도, 음수의 로그값을 계산해도 ... (중략)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_zero_ = tf.log(zero_)\n",
    "log_zero_.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus_one_ = tf.constant(-1.0)\n",
    "log_minus_one_ = tf.log(minus_one_)\n",
    "log_minus_one_.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습 중에 Inf 또는 NaN 이 발생했다면, 외관상 뭔가 계속 학습하는 것 같아도 결과적으로 쓸모없을 수 있음\n",
    "\n",
    "- `tf.check_numerics(a_tensor)`\n",
    "  - `a_tensor` 에 NaN 이나 Inf 값이 들어 있는지 확인. 들어있으면 예외발생.\n",
    "\n",
    "\n",
    "- `tf.add_check_numerics_op()`\n",
    "  - 모든 부동 소숫점 텐서에 `tf.check_numerics()` 계산을 추가\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess.run([ \\\n",
    "          tf.check_numerics(v,'check_numerics {}'.format(v.name)) \\\n",
    "          for v in [\n",
    "              zero_, \n",
    "              minus_one_, \n",
    "              div_by_zero_, \n",
    "              sqrt_minus_one_, \n",
    "              log_zero_, \n",
    "              minus_one_]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬 디버거 [`pdb`](http://devdocs.io/python~2.7/library/pdb) 사용법\n",
    "\n",
    "- `python -m pdb myscript.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `w(here)`\n",
    "\n",
    "-  `d(own)`\n",
    "\n",
    "- `u(p)`\n",
    "\n",
    "- `l(ist)` [_first_[, _last_]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `s(tep)`\n",
    "\n",
    "- `n(ext)`\n",
    "\n",
    "- `unt(il)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `c(ont(inue))`\n",
    "\n",
    "- `r(eturn)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `b(reak)` [[_filename_:]_lineno_|_function_[,_condition_]]\n",
    "\n",
    "> Without argument, list all breaks, including for each breakpoint, the number of times that breakpoint has been hit, the current ignore count, and the associated condition if any.\n",
    "\n",
    "- `disable` [_bpnumber_ [_bpnumber_ …]]\n",
    "\n",
    "- `enable` [_bpnumber_ [_bpnumber_ …]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[!]`_statement_\n",
    "\n",
    "> Execute the (one-line) statement in the context of the current stack frame. The exclamation point can be omitted unless the first word of the statement resembles a debugger command. To set a global variable, you can prefix the assignment command with a global command on the same line, e.g.:\n",
    "\n",
    "    (Pdb) global list_options; list_options = ['-l']\n",
    "    (Pdb)\n",
    "\n",
    "- `p expression`\n",
    "\n",
    "> Note print can also be used, but is not a debugger command — this executes the Python print statement.\n",
    "\n",
    "- `pp expression`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- `a(rgs)`\n",
    "\n",
    "> Print the argument list of the current function.\n",
    "\n",
    "- `run` [_args_ …]\n",
    "\n",
    "> Restart the debugged Python program. If an argument is supplied, it is split with “shlex” and the result is used as the new sys.argv. History, breakpoints, actions and debugger options are preserved. “restart” is an alias for “run”.\n",
    "\n",
    "- `q(uit)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주피터 노트북에서도 pdb 를 쓸 수 있습니다\n",
    "\n",
    "- **`debug`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-161ffdb3c76d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfunction_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-161ffdb3c76d>\u001b[0m in \u001b[0;36mfunction_3\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfunction_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-161ffdb3c76d>\u001b[0m in \u001b[0;36mfunction_2\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-161ffdb3c76d>\u001b[0m in \u001b[0;36mfunction_1\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def function_1(x,y):\n",
    "    return x / y\n",
    "\n",
    "def function_2(x,y):\n",
    "    return function_1(x,y) * x\n",
    "\n",
    "def function_3(x,y):\n",
    "    return function_2(x,y) + x\n",
    "\n",
    "function_3(99,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-37-161ffdb3c76d>\u001b[0m(2)\u001b[0;36mfunction_1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunction_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunction_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mfunction_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 디버거 [`tfdbg`](https://www.tensorflow.org/programmers_guide/debugger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일을 열어 보면 training 할 때 다음과 같이 session 을 새로 만들어 쓰는 것을 볼 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "config = tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "with tf.Session(config=config) as session:\n",
    "\n",
    "  <span style=\"color:red\">session = tf_debug.LocalCLIDebugWrapperSession(session)</span>\n",
    "  session.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "\n",
    "  session.run(tf.global_variables_initializer())\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행\n",
    "\n",
    "        python mnist_with_tf_debug.py --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 2.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    tfdbg> run -t 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 3.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    tfdbg> print_tensor Variable:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 4.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    tfdbg> node_info Variable:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 5.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    tfdbg> list_outputs Variable:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 6.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    tfdbg> run_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"download 7.png\" style=\"width:65.0rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기타 참고자료\n",
    "\n",
    "- [A Practical Guide for Debugging TensorFlow Codes, Jongwook Choi](https://wookayin.github.io/tensorflow-talk-debugging/)\n",
    "- [Jupyter notebooks features](http://arogozhnikov.github.io/2016/09/10/jupyter-features.html)\n",
    "- [IPython built-in magic commands](http://ipython.readthedocs.io/en/stable/interactive/magics.html)\n",
    "- `%quickref`, `%magic`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
